# Nexa Analyzer API

[![CI](https://github.com/FrancoGaytan/nexa-analyzer-api/actions/workflows/ci.yml/badge.svg)](https://github.com/FrancoGaytan/nexa-analyzer-api/actions/workflows/ci.yml)

API (MVP) para extraer r√°pidamente contexto estructurado desde texto libre o documentos (RFPs, briefs) y devolver un JSON m√≠nimo con: objetivos, requisitos t√©cnicos, oportunidades futuras y campos b√°sicos de cliente. Implementado con FastAPI + Pydantic v2. Pr√≥ximo paso: integrar un LLM para enriquecer el an√°lisis.

## Caracter√≠sticas actuales

- Endpoint √∫nico `POST /context/analyze` que acepta:
	- `client_name` (form field obligatorio)
	- `raw_text_blocks` (string JSON opcional: lista de bloques de texto)
	- `files` (0..n archivos: `.txt`, `.pdf`, `.docx`)
- Heur√≠sticas simples (keywords) para detectar objetivos, requisitos t√©cnicos y oportunidades futuras.
- Extracci√≥n de texto de PDF (pypdf), DOCX (python-docx) y TXT.
- Respuesta inmediata siempre con `status = "completed"`.
- Tests automatizados (`pytest`).

## Requisitos

- Python 3.13
- uv instalado (<https://docs.astral.sh/uv/>)

## Instalaci√≥n

```powershell
# Activar entorno (si no se cre√≥, primero: uv venv)
. .\.venv\Scripts\Activate.ps1
uv sync  # instala dependencias declaradas en pyproject.toml
```

## Ejecutar servidor (modo desarrollo)

```powershell
python -m uvicorn app.main:app --reload --port 8000
```

Si `uv run` funciona en tu entorno:

```powershell
uv run uvicorn app.main:app --reload --port 8000
```

## Endpoints

### Health

`GET /health` ‚Üí `{ "status": "ok" }`

### An√°lisis de contexto

`POST /context/analyze`

Content-Type: `multipart/form-data` o `application/x-www-form-urlencoded` (para solo texto). Campos:

- `client_name`: nombre del cliente (string)
- `raw_text_blocks`: (opcional) JSON serializado de lista de strings
- `files`: (opcional) lista de archivos

Ejemplo de respuesta:

```json
{
  "analysis_id": "<uuid>",
  "status": "completed",
  "client_name": "ACME Logistics",
  "summary": {
    "business_overview": null,
    "objectives": ["Reducir costos", "Integrar sistemas existentes"],
    "company_info": null,
    "technical_requirements": ["Integraci√≥n con ERP SAP"],
    "project_timeline": null,
    "additional_context_questions": [],
    "potential_future_opportunities": ["Optimizaci√≥n futura con anal√≠tica avanzada"]
  }
}
```

## Ejemplos (PowerShell / Windows)

### Solo texto

```powershell
curl.exe -X POST ^
  -F "client_name=ACME Logistics" ^
  -F "raw_text_blocks=[\"Queremos reducir costos y mejorar integraci√≥n con SAP.\"]" ^
  http://localhost:8000/context/analyze
```

### Con archivo

```powershell
curl.exe -X POST ^
  -F "client_name=ACME Logistics" ^
  -F "files=@samples/brief.txt" ^
  http://localhost:8000/context/analyze
```

## Estructura (parcial)

```text
app/
  main.py
  api/routes/context.py
  api/routes/health.py
  models/context.py
  services/context_analyzer_service.py
tests/
  test_health.py
  test_context.py
samples/
  brief.txt
```

## Tests

```powershell
uv run pytest -q
```

## Roadmap corto

- [ ] Integrar LLM (OpenAI u otro) para enriquecer summary
- [ ] Persistencia (historial de an√°lisis) con una base ligera (SQLite / Postgres)
- [ ] Logging estructurado + correlaci√≥n de requests
- [ ] Dockerfile + composici√≥n para despliegue
- [ ] Campos adicionales (riesgos, KPIs, stakeholders, confidences)
- [ ] Mejora heur√≠sticas (detecci√≥n timeline, riesgos, m√©tricas)

## Frontend (MVP UI)
- M√°s detalles del flujo agentico: ver [AGENTIC_PIPELINE.md](./AGENTIC_PIPELINE.md)

La carpeta `frontend/` contiene una SPA (Vite + React + Tailwind) para interactuar con el pipeline agentico del backend.

Caracter√≠sticas:

- Carga m√∫ltiples archivos (`.txt`, `.pdf`, `.docx`).
- Validaci√≥n de extensiones soportadas.
- Campo de cliente y flag opcional de enriquecimiento (`enrich_allowed`).
- Llamada al endpoint `POST /context/analyze` usando `multipart/form-data`.
- Render estructurado del resultado (campos nuevos: `industry`, `location`, `engagement_age`, etc.).
- Vista expandible con el JSON completo.

### Ejecutar el Frontend

Requisitos: Node 18+ (recomendado), pnpm o npm.

```powershell
cd frontend
# Instalar dependencias
npm install

# Copiar .env.example si se desea cambiar la URL del backend
Copy-Item .env.example .env  # (opcional)

# Ejecutar en modo dev (abre en http://localhost:5173)
npm run dev
```

Si el backend corre en otro puerto/host, ajustar `VITE_API_BASE_URL` en `.env`.

### Build de producci√≥n

```powershell
npm run build
npm run preview # (sirve para testear el build)
```

### Notas

- El backend ahora usa agentes (Ingestor ‚Üí Extractor ‚Üí Validator ‚Üí Researcher opcional) con OpenAI GPT-4o.
- Si se marca "Permitir enriquecimiento" se ejecuta el ResearcherAgent y puede demorar m√°s.
- La respuesta m√≠nima incluye `analysis_id`, `status` y `summary` (ClientContext).
- Se ignoran archivos duplicados por nombre en la sesi√≥n de carga.
- Posibles mejoras futuras: barra de progreso, drag & drop, l√≠mites de tama√±o, internacionalizaci√≥n, theming, pooling de estados si se hace async largo.

## CI

Se incluye workflow de GitHub Actions para correr tests en cada push/PR.

## Licencia

MIT (ver archivo `LICENSE`).

## Contribuciones

Pull requests bienvenidas mientras el alcance siga el roadmap minimal.

---

> MVP orientado a acelerar discovery inicial antes de la integraci√≥n de modelos generativos.

---

## üöÄ Integraci√≥n AutoGen (Pipeline de Agentes)

Se ha incorporado una arquitectura basada en agentes usando la librer√≠a **AutoGen (agentchat + core + ext[openai])** con el modelo `gpt-4o` para transformar materiales de entrada (RFPs, briefs, URLs) en un JSON estructurado listo para ser consumido por otros sistemas o agentes.

### Agentes

| Agente | Responsabilidad | Input | Output |
|--------|-----------------|-------|--------|
| Ingestor | Lee archivos (PDF, DOCX, TXT) o URLs y normaliza el texto, agregando metadatos (p√°ginas, anchors). | Ruta de archivo / URL | `{ text_blocks: [...], metadata: {...} }` |
| Extractor | Convierte bloques de texto + metadatos en el esquema de negocio (`ClientContext`), con evidencias (anchors). | `text_blocks`, `metadata` | JSON parcial con campos + `evidence` |
| Validator | Valida contra el modelo Pydantic (`ClientContext`), intenta reparar campos faltantes. | JSON extra√≠do | JSON validado / reparado |
| Researcher (opcional) | Enriquece campos faltantes usando informaci√≥n p√∫blica (si est√° permitido). | JSON validado | JSON enriquecido + `sources` |
| Coordinator | Orquesta el flujo completo y devuelve el resultado final + log. | Par√°metros de request | `{ final_json, log }` |

### Flujo

1. El endpoint `/context/analyze` recibe archivos o texto plano.
2. `CoordinatorAgent.run_pipeline()` ejecuta secuencialmente:
   - `IngestorAgent.ingest()` ‚Üí extracci√≥n y normalizaci√≥n.
   - `ExtractorAgent.extract()` (async) ‚Üí generaci√≥n estructurada usando LLM.
   - `ValidatorAgent.validate()` (async) ‚Üí verificaci√≥n / reparaci√≥n.
   - `ResearcherAgent.enrich()` (async, condicional) ‚Üí enriquecimiento externo.
3. Se construye un `AnalyzeResponse` con los campos del modelo `ClientContext`.

### Async / LLM

- Los m√©todos de extracci√≥n, validaci√≥n y enriquecimiento son `async` y usan `await agent.run(task=...)` para interactuar con el modelo.
- La respuesta del LLM se parsea en JSON directo; si el modelo incluye texto adicional, se aplica un fallback regex controlado.

### Archivos Clave

```text
app/services/agentic/
  ingestor_agent.py       # Lectura de PDF/DOCX/TXT/URL y normalizaci√≥n
  extractor_agent.py      # LLM ‚Üí JSON estructurado + evidencias
  validator_agent.py      # Validaci√≥n Pydantic + reparaci√≥n asistida por LLM
  researcher_agent.py     # Enriquecimiento p√∫blico opcional
  coordinator_agent.py    # Orquestaci√≥n del pipeline async
```

### Ejemplo Simplificado de Uso Interno

```python
from app.services.agentic.coordinator_agent import CoordinatorAgent

coordinator = CoordinatorAgent()
result = await coordinator.run_pipeline(file_path="./samples/brief.txt", enrich_allowed=False)
print(result["final_json"])
```

### Variables de Entorno

Aseg√∫rate de definir `OPENAI_API_KEY` en `.env` y cargarlo temprano en `app/main.py`:

```python
from dotenv import load_dotenv
load_dotenv()
```

### Manejo de Errores

- Si el LLM no produce JSON v√°lido: se retorna `{ "error": ..., "raw_response": ... }` en la etapa correspondiente.
- Validaciones fallidas: el `ValidatorAgent` intenta reparaci√≥n; si no es posible, conserva campos vac√≠os.
- Enriquecimiento deshabilitado: `ResearcherAgent` devuelve `{ "error": "Enrichment not allowed." }` y el pipeline contin√∫a.


### Estado Actual

- Pipeline funcional MVP.
- Falta: tests espec√≠ficos para cada agente y mocks de LLM. Eliminar metodos deprecados

---
